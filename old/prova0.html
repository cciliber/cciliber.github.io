<!DOCTYPE html>
<html>

<head>
  <meta name="keywords" content="Alessandro Rudi, Machine Learning, Large Scale, Big Data, Nystrom, Kernel, Random Features, Kernel PCA, LCSL, MIT, Massachusetts Institute of Technology, IIT, Laboratory of Computational and Statistical Learning">
  <meta name="description" content="Alessandro Rudi's Academic web page">
  <title>Alessandro Rudi Home Page @ INRIA</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="http://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="prova0.css"> </head>

<body>
  <div class="navbar navbar-default navbar-fixed-top navbar-inverse" id="mainNav">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar-ex-collapse"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button>
        <a class="navbar-brand" href="#"><span>Alessandro Rudi</span></a>
      </div>
      <div class="collapse navbar-collapse" id="navbar-ex-collapse">
        <ul class="nav navbar-nav navbar-right">
          <li class="active">
            <a href="#home" class="page-scroll">Home</a>
          </li>
          <li>
            <a href="#publications" class="page-scroll">Publications</a>
          </li>
          <li>
            <a href="Alessandro_Rudi_CV.pdf" target="_blank">CV
              <br> </a>
          </li>
        </ul>
      </div>
    </div>
  </div>
  <div class="cover" id="home">
    <div class="background-image-fixed cover-image" style="background-image: url('https://unsplash.imgix.net/reserve/nTr1589kTgyXCOdStCGm_MikaRuusunen.jpg?w=1920&amp;q=50&amp;fm=jpg&amp;s=ebc5195bf9546b2a2f21d8df6fd40fe1')"></div>
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <div class="section">
            <div class="background-image img-thumbnail" style="opacity:0.8"></div>
            <div class="container">
              <div class="row">
                <div class="col-md-3">
                  <img src="ale_rudi.png" class="center-block img-responsive img-thumbnail"> </div>
                <div class="col-md-9">
                  <h1>Alessandro Rudi</h1>
                  <h3>Researcher at INRIA, Sierra team, Paris
                    <br> </h3>
                  <h2>alessandro.rudi@inria.fr</h2>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div class="section" id="publications">
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <h1 class="text-center">Publications
            <br> </h1>
        </div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="container">
      <div class="row">
        <div class="col-md-4">
          <img src="papers/colt16/ny_vs_randf.svg" class="img-responsive"> </div>
        <div class="col-md-8">
          <h1><i class="fa fa-fw text-warning -alt fa-eye"></i>Generalization Properties of
            <br>Learning with Random Features</h1>
          <p>We study the generalization properties of regularized learning with random features in the statistical learning theory framework. We show that optimal learning errors can be achieved with a number of features smaller than the number of examples.
            As a byproduct, we also show that learning with random features can be seen as a form of regularization, rather than only a way to speed up computations.</p>
          <p class="lead">Alessandro Rudi, Lorenzo Rosasco
            <br> <span class="text-success">
                <b>NIPS 2017 (ORAL)</b>
              </span></p>
          <div class="btn-group">
            <a class="btn btn-default" target="_blank" href="http://arxiv.org/pdf/1602.04474">PDF</a>
            <a href="#" class="btn btn-default" data-target="#colt16" data-toggle="modal">BibTex</a>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div class="modal fade" id="colt16">
    <div class="modal-dialog modal-lg">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
          <h4 class="modal-title">Generalization Properties of Learning with Random Features</h4>
        </div>
        <div class="modal-body lead">
          <p></p>
          <div>@article{rudi2016genrf,</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;author = {Rudi, Alessandro and Camoriano, Raffaello and Rosasco, Lorenzo},</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;title = {Generalization Properties of Learning with Random Features},</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;journal = {ArXiv e-prints},</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;archivePrefix = "arXiv",</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;eprint = {1602.04474},</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;primaryClass = "stat.ML",</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;keywords = {Statistics - Machine Learning},</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;year = 2016,</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;month = {feb}</div>
          <div>}</div>
          <p></p>
        </div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="container">
      <div class="row">
        <div class="col-md-7">
          <h1>A Consistent Regularization Approach for Structured Prediction</h1>
          <div> <span style="line-height: 1.42857143;">We propose and analyze a regularization approach for structured prediction
                problems. We characterize a large class of loss functions that allows to
                naturally embed structured outputs in a linear space. We exploit this fact
                to design learning algorithms using a surrogate loss approach and regularization
                techniques. We prove universal consistency and finite sample bounds characterizing
                the generalization properties of the proposed methods. Experimental results
                are provided to demonstrate the practical usefulness of the proposed approach.&nbsp;</span> </div>
          <p class="lead">Carlo Ciliberto, Alessandro Rudi, Lorenzo Rosasco
            <br> <span class="text-success">
                <b>NIPS 2016</b>
              </span> </p>
          <div class="btn-group">
            <a class="btn btn-default" target="_blank" href="https://arxiv.org/pdf/1605.07588">PDF</a>
            <a class="btn btn-default" target="_blank" href="papers/nips16/structured-prediction-Rudi-NIPS16.pdf">Slides</a>
            <a href="#" class="btn btn-default" data-target="#nips16" data-toggle="modal">BibTex</a>
          </div>
        </div>
        <div class="col-md-5">
          <img src="papers/nips16/surrogate.png" class="img-responsive"> </div>
      </div>
    </div>
  </div>
  <div class="modal fade" id="nips16">
    <div class="modal-dialog modal-lg">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
          <h4 class="modal-title">A Consistent Regularization Approach for Structured Prediction</h4>
        </div>
        <div class="modal-body lead">
          <p>@incollection{cilib2016structpred,
            <br>&nbsp; &nbsp;title = {A Consistent Regularization Approach for Structured Prediction},
            <br>&nbsp; &nbsp;author = {Ciliberto, Carlo and Rosasco, Lorenzo and Rudi, Alessandro},
            <br>&nbsp; &nbsp;booktitle = {Advances in Neural Information Processing Systems 29},
            <br>&nbsp; &nbsp;editor = {D. D. Lee and M. Sugiyama and U. V. Luxburg and I. Guyon and R. Garnett},
            <br>&nbsp; &nbsp;pages = {4412--4420},
            <br>&nbsp; &nbsp;year = {2016},
            <br>&nbsp; &nbsp;publisher = {Curran Associates, Inc.},
            <br>&nbsp; &nbsp;url = {http://papers.nips.cc/paper/6093-a-consistent-regularization-approach-for-structured-prediction.pdf}
            <br>}
            <br> </p>
        </div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="container">
      <div class="row">
        <div class="col-md-4">
          <img src="papers/aistats2016/img1.png" class="img-responsive"> </div>
        <div class="col-md-8">
          <h2 contenteditable="true">NYTRO: When Subsampling Meets Early Stopping</h2>
          <p>Early stopping is a well known approach to reduce the time complexity for performing training and model selection of large scale learning machines. On the other hand, memory/space (rather than time) complexity is the main constraint in many
            applications, and randomized subsampling techniques have been proposed to tackle this issue. In this paper we ask whether early stopping and subsampling ideas can be combined in a fruitful way. We consider the question in a least squares regression
            setting and propose a form of randomized iterative regularization based on early stopping and subsampling. In this context, we analyze the statistical and computational properties of the proposed method. Theoretical results are complemented
            and validated by a thorough experimental analysis.</p>
          <p class="lead">T. Angles, R. Camoriano, A. Rudi, L. Rosasco
            <br> <span class="lead text-success">
                <b>AISTATS 2016</b>
              </span> </p>
          <div class="btn-group">
            <a class="btn btn-default" target="_blank" href="http://arxiv.org/abs/1510.05684">PDF</a>
            <a href="#" class="btn btn-default" data-target="#aistats2016" data-toggle="modal">BibTex</a>
            <a class="btn btn-default" href="http://lcsl.github.io/NYTRO/">Library</a>
          </div>
        </div>
      </div>
    </div>
  </div>
  <div class="modal fade" id="aistats2016">
    <div class="modal-dialog modal-lg">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
          <h4 class="modal-title">NYTRO: When Subsampling Meets Early Stopping</h4>
        </div>
        <div class="modal-body lead">
          <p></p>
          <div>@article{nytro2015,</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;author = {{Angles}, T. and {Camoriano}, R. and {Rudi}, A. and {Rosasco}, L.},</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;title = "{NYTRO: When Subsampling Meets Early Stopping}",</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;journal = {ArXiv e-prints},</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;archivePrefix = "arXiv",</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;eprint = {1510.05684},</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;primaryClass = "stat.ML",</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;keywords = {Statistics - Machine Learning},</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;year = 2015,</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;month = oct,</div>
          <div>&nbsp;&nbsp;&nbsp;&nbsp;adsurl = {http://adsabs.harvard.edu/abs/2015arXiv151005684A},</div>
          <div>}</div>
          <p></p>
        </div>
      </div>
    </div>
  </div>
  <div class="container">
    <div class="row">
      <div class="col-md-8">
        <div class="col-md-12">
          <h2> <i class="fa fa-fw text-warning -alt fa-eye"></i>Less is More: Nyström Computational Regularization</h2>
          <p>We study Nyström type subsampling approaches to large scale kernel methods, and prove learning bounds in the statistical learning setting, where random sampling and high probability estimates are considered. In particular, we prove that these
            approaches can achieve optimal learning rates, provided the subsampling level is suitably chosen. These results suggest a simple incremental variant of Nyström Kernel Regularized Least Squares, where the subsampling level implements a form
            of computational regularization, in the sense that it controls at the same time regularization and computations. Extensive experimental analysis shows that the considered approach achieves state of the art performances on benchmark large scale
            datasets.</p>
          <p class="lead">Alessandro Rudi, Raffaello Camoriano, Lorenzo Rosasco
            <br> <span class="text-success">
                <b>NIPS 2015 (ORAL)</b>
              </span> </p>
          <div class="btn-group">
            <a class="btn btn-default" target="_blank" href="http://papers.nips.cc/paper/5936-less-is-more-nystrom-computational-regularization.pdf">PDF</a>
            <a href="#" class="btn btn-default" data-target="#nips15" data-toggle="modal">BibTex</a>
            <a class="btn btn-default" href="papers/nips15/slides_NIPS2015_less_is_more.pdf">Slides</a>
            <a class="btn btn-default" href="http://lcsl.github.io/NystromCoRe/">Library</a>
          </div>
        </div>
      </div>
      <div class="col-md-4">
        <img src="papers/nips15/m_lambda_plot.svg" class="img-responsive"> </div>
    </div>
  </div>
  <div class="fade modal text-left" id="nips15">
    <div class="modal-dialog modal-lg">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
          <h4 class="modal-title" id="myModalLabel">Less is More: Nystrom Computational Regularization (BibTex)</h4>
        </div>
        <div class="modal-body lead">
          <p></p>
          <div>@incollection{rudi2015less,</div>
          <div>&nbsp; &nbsp; &nbsp;title = {Less is More: Nystr\"{o}m Computational Regularization},</div>
          <div>&nbsp; &nbsp; &nbsp;author = {Rudi, Alessandro and Camoriano, Raffaello and Rosasco, Lorenzo},</div>
          <div>&nbsp; &nbsp; &nbsp;booktitle = {Advances in Neural Information Processing Systems 28},</div>
          <div>&nbsp; &nbsp; &nbsp;editor = {C. Cortes and N.D. Lawrence and D.D. Lee and M. Sugiyama and R. Garnett and R. Garnett},</div>
          <div>&nbsp; &nbsp; &nbsp;pages = {1648--1656},</div>
          <div>&nbsp; &nbsp; &nbsp;year = {2015},</div>
          <div>&nbsp; &nbsp; &nbsp;publisher = {Curran Associates, Inc.},</div>
          <div>&nbsp; &nbsp; &nbsp;url = {http://papers.nips.cc/paper/5936-less-is-more-nystrom-computational-regularization.pdf}</div>
          <div>}</div>
          <p></p>
        </div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="container">
      <div class="row">
        <div class="col-md-6">
          <h1>Learning Sets and Subspaces</h1>
          <p>We consider here the classic problem of support estimation, or learning a set from random samples, and propose a natural but novel approach to address it. We do this by investigating its connection with a seemingly distinct problem, namely subspace
            learning.</p>
          <p> <span class="lead">A. Rudi, G. D. Canas, E. De Vito, L. Rosasco</span>
            <br> <span class="lead text-success">
                <b>Regularization, Optimization, Kernels, and Support Vector Machines - 2014
                  (Book Chapter)</b>
              </span> </p>
          <div class="btn-group">
            <a href="http://www.researchgate.net/profile/Alessandro_Rudi/publication/269394837_Learning_Sets_and_Subspaces/links/54889caa0cf289302e30b65f.pdf" class="btn btn-default" target="_blank">PDF</a>
            <a href="#" class="btn btn-default" data-toggle="modal" data-target="#book-roks-2014">BibTex</a>
          </div>
        </div>
        <div class="col-md-6">
          <br>
          <br>
          <img class="img-responsive" src="papers/book-2014/book-14.svg" style=""> </div>
      </div>
    </div>
  </div>
  <div class="modal fade" id="book-roks-2014">
    <div class="modal-dialog modal-lg">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
          <h4 class="modal-title">Learning Sets and Subspaces (BibTex)</h4>
        </div>
        <div class="modal-body">
          <p class="lead">@incollection{rudi2014learning,
            <br>&nbsp; &nbsp; &nbsp; &nbsp;title={Learning Sets and Subspaces},
            <br>&nbsp; &nbsp; &nbsp; &nbsp;author={Rudi, Alessandro and Canas, G. D. and De Vito, Ernesto and Rosasco, Lorenzo},
            <br>&nbsp; &nbsp; &nbsp; &nbsp;booktitle={Regularization, Optimization, Kernels, and Support Vector Machines},
            <br>&nbsp; &nbsp; &nbsp; &nbsp;pages={337--357},
            <br>&nbsp; &nbsp; &nbsp; &nbsp;year={2014},
            <br>&nbsp; &nbsp; &nbsp; &nbsp;publisher={CRC Press}
            <br>}</p>
        </div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="container">
      <div class="row">
        <div class="col-md-5">
          <img src="papers/prl-14/00_spere-planes-new1.jpg" class="img-responsive"> </div>
        <div class="col-md-7">
          <h1>Geometrical and Computational aspects of Spectral Support Estimation for Novelty Detection</h1>
          <p>In this paper we discuss the Spectral Support Estimation algorithm [1] by analyzing its geometrical and computational properties. The estimator is non-parametric and the model selection depends on three parameters whose role is clarified by
            simulations on a two-dimensional space. The performance of the algorithm for novelty detection is tested and compared with its main competitors on a collection of real benchmark datasets of different sizes and types.</p>
          <p class="lead">Alessandro Rudi, Francesca Odone, Ernesto De Vito
            <br> <span class="text-success">
                <b>Pattern Recognition Letters - 2014 (Journal)</b>
              </span> </p>
        </div>
        <div class="btn-group">
          <a class="btn btn-default" target="_blank" href="https://www.researchgate.net/profile/Ernesto_De_Vito/publication/259118407_Geometrical_and_computational_aspects_of_Spectral_Support_Estimation_for_novelty_detection/links/02e7e52a6f38b74f73000000.pdf">PDF</a>
          <a href="#" class="btn btn-default" data-toggle="modal" data-target="#prl-2014">BibTex</a>
        </div>
      </div>
    </div>
  </div>
  <div class="modal fade" id="prl-2014">
    <div class="modal-dialog modal-lg">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
          <h4 class="modal-title">Geometrical and Computational aspects of Spectral Support Estimation for Novelty Detection (BibTex)</h4>
        </div>
        <div class="modal-body">
          <p class="lead">@article{rudi2014geometrical,
            <br>&nbsp; &nbsp; &nbsp; &nbsp; title={Geometrical and computational aspects of Spectral Support Estimation for novelty detection},
            <br>&nbsp; &nbsp; &nbsp; &nbsp; author={Rudi, Alessandro and Odone, Francesca and De Vito, Ernesto},
            <br>&nbsp; &nbsp; &nbsp; &nbsp; journal={Pattern Recognition Letters},
            <br>&nbsp; &nbsp; &nbsp; &nbsp; volume={36},
            <br>&nbsp; &nbsp; &nbsp; &nbsp; pages={107--116},
            <br>&nbsp; &nbsp; &nbsp; &nbsp; year={2014},
            <br>&nbsp; &nbsp; &nbsp; &nbsp; publisher={North-Holland}
            <br>}</p>
        </div>
      </div>
    </div>
  </div>
  <div class="section">
    <div class="container">
      <div class="row">
        <div class="col-md-7">
          <h1>On the Sample Complexity of Subspace Learning</h1>
          <p class="text-justify">A large number of algorithms in machine learning, from principal component analysis (PCA), and its non-linear (kernel) extensions, to more recent spectral embedding and support estimation methods, rely on estimating a linear subspace from samples.
            In this paper we introduce a general formulation of this problem and derive novel learning error estimates. Our results rely on natural assumptions on the spectral properties of the covariance operator associated to the data distribution,
            and hold for a wide class of metrics between subspaces. As special cases, we discuss sharp error estimates for the reconstruction properties of PCA and spectral support estimation. Key to our analysis is an operator theoretic approach that
            has broad applicability to spectral learning methods.</p>
          <p class="lead">Alessandro Rudi, Guillermo D. Canas, Lorenzo Rosasco
            <br> <b class="text-success">NIPS 2013</b> </p>
          <div class="btn-group">
            <a class="btn btn-default" target="_blank" href="http://papers.nips.cc/paper/4945-on-the-sample-complexity-of-subspace-learning">PDF</a>
            <a href="#" class="btn btn-default" data-toggle="modal" data-target="#nips-2013">BibTex</a>
          </div>
        </div>
        <div class="col-md-5">&nbsp;
          <img src="papers/nips13/kstar.png" class="img-responsive"> </div>
      </div>
    </div>
  </div>
  <div class="modal fade" id="nips-2013">
    <div class="modal-dialog modal-lg">
      <div class="modal-content">
        <div class="modal-header">
          <button type="button" class="close" data-dismiss="modal" aria-hidden="true">×</button>
          <h4 class="modal-title">On the Sample Complexity of Subspace Learning (BibTex)</h4>
        </div>
        <div class="modal-body">
          <p class="lead">@inproceedings{rudi2013sample,
            <br>&nbsp; &nbsp; &nbsp; &nbsp; title={On the sample complexity of subspace learning},
            <br>&nbsp; &nbsp; &nbsp; &nbsp; author={Rudi, Alessandro and Canas, Guillermo D and Rosasco, Lorenzo},
            <br>&nbsp; &nbsp; &nbsp; &nbsp; booktitle={Advances in Neural Information Processing Systems},
            <br>&nbsp; &nbsp; &nbsp; &nbsp; pages={2067--2075},
            <br>&nbsp; &nbsp; &nbsp; &nbsp; year={2013}
            <br>}</p>
        </div>
      </div>
    </div>
  </div>
  <script type="text/javascript" src="http://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
  <script type="text/javascript" src="http://netdna.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
  <script type="text/javascript" src="wow.min.js"></script>
  <script type="text/javascript" src="creative.js"></script>
  <script type="text/javascript" src="cbpAnimatedHeader.js"></script>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                                                                                                                      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
                                                                                                                      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
                                                                                                                      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
                                                                                                                    
                                                                                                                      ga('create', 'UA-66174202-1', 'auto');
                                                                                                                      ga('send', 'pageview');
  </script>
</body>

</html>